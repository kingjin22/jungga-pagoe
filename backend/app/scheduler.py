"""
APScheduler Î∞±Í∑∏ÎùºÏö¥Îìú ÏûêÎèô ÏûëÏóÖ
- Îß§ 10Î∂Ñ  : Ïø†Ìå° Îîú sync + Í∞ÄÍ≤© Í≤ÄÏ¶ù
- Îß§ 1ÏãúÍ∞Ñ : ÎÑ§Ïù¥Î≤Ñ Îîú sync
- Îß§ 1ÏãúÍ∞Ñ : Í∞ÄÍ≤© Í≤ÄÏ¶ù (Îì±Î°ùÎêú Îîú ÌòÑÏû¨ Í∞ÄÍ≤© Ï≤¥ÌÅ¨ ‚Üí Í∞ÄÍ≤© Ïò§Î•¥Î©¥ ÏûêÎèô ÎπÑÌôúÏÑ±)
"""
import asyncio
import logging
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger

logger = logging.getLogger(__name__)

scheduler = AsyncIOScheduler()


async def _sync_coupang():
    # Ïø†Ìå° ÌååÌä∏ÎÑàÏä§ API ÏäπÏù∏ Ï†ÑÍπåÏßÄ ÎπÑÌôúÏÑ±Ìôî
    # ÏÉòÌîå Îç∞Ïù¥ÌÑ∞(link.coupang.com/sample)Îäî Ïù¥ÎØ∏ÏßÄ ÏóÜÍ≥† ÎßÅÌÅ¨ Î∂àÌÜµ ‚Üí ÏÇ¨Ïö©Ïûê Í≤ΩÌóò ÏµúÏïÖ
    # ÌååÌä∏ÎÑàÏä§ ÏäπÏù∏ ÌõÑ partners.coupang.comÏóêÏÑú API ÌÇ§ Î∞õÏïÑ ÌôúÏÑ±Ìôî
    logger.info("‚è∏ Ïø†Ìå° sync ÎπÑÌôúÏÑ±Ìôî (ÌååÌä∏ÎÑàÏä§ ÏäπÏù∏ ÎåÄÍ∏∞ Ï§ë)")
    return


async def _sync_naver():
    try:
        import app.db_supabase as db
        from app.services.naver import collect_real_deals
        from app.services.deal_validator import validator
        deals_data = await collect_real_deals(limit_per_keyword=5)
        created = skipped = 0
        for item in deals_data:
            if db.deal_url_exists(item["product_url"]):
                continue
            v = validator.validate_sync(item)
            if not v:
                logger.debug(f"[ÎÑ§Ïù¥Î≤Ñskip] {v.reason}")
                skipped += 1
                continue
            # Ï†úÎ™©+Í∞ÄÍ≤© Ï§ëÎ≥µ Ï≤¥ÌÅ¨ (URL Îã¨ÎùºÎèÑ ÎèôÏùº Ï†úÌíà Î∞©ÏßÄ)
            if db.deal_duplicate_exists(item["title"], v.sale_price):
                skipped += 1
                continue
            db.create_deal({
                "title": item["title"],
                "original_price": v.original_price,
                "sale_price": v.sale_price,
                "discount_rate": v.discount_rate,
                "image_url": item.get("image_url"),
                "product_url": item["product_url"],
                "source": "naver",
                "category": item.get("category", "Í∏∞ÌÉÄ"),
                "status": "active",
                "is_hot": v.is_hot,
            })
            created += 1
        logger.info(f"‚úÖ ÎÑ§Ïù¥Î≤Ñ sync: {created}Í∞ú Ï†ÄÏû• | {skipped}Í∞ú Ï†úÏô∏")
    except Exception as e:
        logger.error(f"‚ùå ÎÑ§Ïù¥Î≤Ñ sync: {e}")


async def _sync_ppomppu():
    # ‚õî ÏòÅÍµ¨ ÎπÑÌôúÏÑ±Ìôî ‚Äî Naver lprice Í∏∞Î∞ò Í≤ÄÏ¶ùÏúºÎ°úÎäî Îîú ÏÜåÏßÑ Í∞êÏßÄ Î∂àÍ∞Ä
    # Ïã§Ï†ú ÏáºÌïëÎ™∞ ÌéòÏù¥ÏßÄ ÏßÅÏ†ë Í∞ÄÍ≤© ÌÅ¨Î°§ÎßÅ Íµ¨ÌòÑ Ï†ÑÍπåÏßÄ ÏàòÏßë Ï§ëÎã®
    logger.info("‚õî ÎΩêÎøå sync ÎπÑÌôúÏÑ±Ìôî")
    return
    try:
        import app.db_supabase as db
        from app.services.ppomppu import fetch_ppomppu_deals
        from app.services.price_scrapers import check_community_deal_price
        from app.config import settings

        deals_data = await fetch_ppomppu_deals()
        created = skipped = 0

        async with __import__("httpx").AsyncClient(timeout=8) as client:
            for item in deals_data:
                sale = float(item.get("sale_price") or 0)
                is_free = sale == 0

                # ÌíàÏßà Í∏∞Ï§Ä: Ïù¥ÎØ∏ÏßÄ + Ïã§Ï†ú ÏáºÌïëÎ™∞ URL (Î¨¥Î£å Ï†úÏô∏)
                if not is_free:
                    has_image = bool(item.get("image_url"))
                    has_real_url = bool(item.get("product_url") and "ppomppu.co.kr" not in item["product_url"])
                    if not (has_image and has_real_url):
                        skipped += 1
                        continue

                if db.deal_url_exists(item["product_url"]):
                    continue

                if is_free:
                    # Î¨¥Î£åÎîúÏùÄ Í≤ÄÏ¶ù ÏóÜÏù¥ Ï†ÄÏû•
                    db.create_deal({
                        "title": item["title"],
                        "original_price": 0,
                        "sale_price": 0,
                        "discount_rate": 100,
                        "image_url": item.get("image_url"),
                        "product_url": item["product_url"],
                        "source": "community",
                        "category": item.get("category", "Í∏∞ÌÉÄ"),
                        "status": "active",
                        "is_hot": False,
                        "submitter_name": item.get("submitter_name", "ÎΩêÎøå"),
                    })
                    created += 1
                    continue

                # ‚îÄ‚îÄ Ïã§ÏãúÍ∞Ñ Í∞ÄÍ≤© Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                price_check = await check_community_deal_price(
                    title=item["title"],
                    community_price=sale,
                    naver_client_id=settings.NAVER_CLIENT_ID,
                    naver_client_secret=settings.NAVER_CLIENT_SECRET,
                    client=client,
                )
                if not price_check:
                    logger.debug(f"[ÎΩêÎøåskip] {price_check.reason} | {item['title'][:40]}")
                    skipped += 1
                    continue

                # Ï§ëÎ≥µ Ï≤¥ÌÅ¨ (ÎÑ§Ïù¥Î≤Ñ Ïπ¥ÌÉàÎ°úÍ∑∏ URL Í∏∞Ï§Ä)
                final_url = price_check.naver_product_url or item["product_url"]
                if db.deal_url_exists(final_url):
                    skipped += 1
                    continue
                if db.deal_duplicate_exists(item["title"], price_check.community_price):
                    skipped += 1
                    continue

                db.create_deal({
                    "title": item["title"],
                    "description": item.get("description"),
                    "original_price": price_check.naver_hprice or price_check.naver_lprice,
                    "sale_price": price_check.community_price,
                    "discount_rate": price_check.discount_vs_hprice,
                    "image_url": item.get("image_url") or price_check.image_url,
                    "product_url": final_url,
                    "source": "community",
                    "category": item.get("category", "Í∏∞ÌÉÄ"),
                    "status": "active",
                    "is_hot": price_check.discount_vs_hprice >= 20,
                    "submitter_name": item.get("submitter_name", "ÎΩêÎøå"),
                    "admin_note": f"Ïã§ÏãúÍ∞Ñ Í≤ÄÏ¶ù: lprice={price_check.naver_lprice:,.0f}Ïõê",
                })
                logger.info(f"  ‚úÖ Ï†ÄÏû•: {item['title'][:40]} | -{price_check.discount_vs_hprice}%")
                created += 1

        logger.info(f"‚úÖ ÎΩêÎøå sync: {created}Í∞ú Ï†ÄÏû• | {skipped}Í∞ú Ï†úÏô∏")
    except Exception as e:
        logger.error(f"‚ùå ÎΩêÎøå sync: {e}")


async def _sync_naver_cafe():
    # ‚õî ÏòÅÍµ¨ ÎπÑÌôúÏÑ±Ìôî ‚Äî Ïª§ÎÆ§ÎãàÌã∞ Îîú Ïã†Î¢∞ÏÑ± Î¨∏Ï†ú
    logger.info("‚õî Ï†ïÍ∞ÄÍ±∞Î∂Ä Ïπ¥Ìéò sync ÎπÑÌôúÏÑ±Ìôî")
    return
    try:
        import app.db_supabase as db
        from app.services.naver_cafe import fetch_naver_cafe_deals

        deals_data = await fetch_naver_cafe_deals()
        created = skipped = 0

        from app.services.price_scrapers import check_community_deal_price
        from app.config import settings

        async with __import__("httpx").AsyncClient(timeout=8) as client:
            for item in deals_data:
                if db.deal_url_exists(item.get("product_url", "")):
                    skipped += 1
                    continue
                if db.deal_duplicate_exists(item["title"], item.get("sale_price", 0)):
                    skipped += 1
                    continue

                # naver_cafeÎäî Ïù¥ÎØ∏ naver Í≤ÄÏÉâ ÏôÑÎ£å ‚Üí Îîú ÏÜåÏßÑ Ïó¨Î∂ÄÎßå Ïû¨ÌôïÏù∏
                price_check = await check_community_deal_price(
                    title=item["title"],
                    community_price=float(item.get("sale_price") or 0),
                    naver_client_id=settings.NAVER_CLIENT_ID,
                    naver_client_secret=settings.NAVER_CLIENT_SECRET,
                    client=client,
                )
                if not price_check:
                    logger.debug(f"[Ïπ¥Ìéòskip] {price_check.reason} | {item['title'][:40]}")
                    skipped += 1
                    continue

                db.create_deal({
                    "title": item["title"],
                    "description": item.get("description"),
                    "original_price": price_check.naver_hprice or price_check.naver_lprice,
                    "sale_price": price_check.community_price,
                    "discount_rate": price_check.discount_vs_hprice,
                    "image_url": item.get("image_url") or price_check.image_url,
                    "product_url": price_check.naver_product_url or item.get("product_url"),
                    "source": "community",
                    "category": item.get("category", "Í∏∞ÌÉÄ"),
                    "status": "active",
                    "is_hot": price_check.discount_vs_hprice >= 20,
                    "submitter_name": item.get("submitter_name", "Ï†ïÍ∞ÄÍ±∞Î∂Ä"),
                    "admin_note": f"Ïã§ÏãúÍ∞Ñ Í≤ÄÏ¶ù: lprice={price_check.naver_lprice:,.0f}Ïõê",
                })
                created += 1

        logger.info(f"‚úÖ Ï†ïÍ∞ÄÍ±∞Î∂Ä Ïπ¥Ìéò: {created}Í∞ú Ïã†Í∑ú | {skipped}Í∞ú Ïä§ÌÇµ")
    except Exception as e:
        logger.error(f"‚ùå Ï†ïÍ∞ÄÍ±∞Î∂Ä Ïπ¥Ìéò sync: {e}")


async def _verify_prices():
    logger.info("üîç Í∞ÄÍ≤© Í≤ÄÏ¶ù ÏãúÏûë...")
    try:
        import app.db_supabase as db
        from app.services.price_checker import verify_deal, MAX_FAIL_COUNT
        from datetime import datetime, timedelta
        cutoff = (datetime.utcnow() - timedelta(minutes=8)).isoformat()
        deals = db.get_deals_for_verify(cutoff)
        logger.info(f"  Í≤ÄÏ¶ù ÎåÄÏÉÅ: {len(deals)}Í∞ú")
        from app.services.price_scrapers import RealtimePriceChecker
        from app.config import settings
        rt_checker = RealtimePriceChecker(settings.NAVER_CLIENT_ID, settings.NAVER_CLIENT_SECRET)

        ok = changed = expired_count = 0
        async with __import__("httpx").AsyncClient(timeout=8) as hclient:
          for deal in deals:
            try:
                # Ïª§ÎÆ§ÎãàÌã∞ Îîú: Ìï´Îîú ÏÜåÏßÑ Ïó¨Î∂Ä Ïã§ÏãúÍ∞Ñ Ïû¨ÌôïÏù∏
                if deal.get("source") == "community" and deal.get("sale_price"):
                    rt = await rt_checker.recheck_existing(
                        title=deal["title"],
                        stored_sale_price=float(deal["sale_price"]),
                        client=hclient,
                    )
                    if rt["action"] == "expired":
                        logger.info(f"  üõë Ïª§ÎÆ§ÎãàÌã∞ Îîú ÏÜåÏßÑ: {deal['title'][:40]} | {rt['reason']}")
                        db.update_deal_verify(deal["id"], {"status": "expired", "verify_fail_count": 0})
                        expired_count += 1
                        continue

                check = await verify_deal(deal)
                patch = {"last_verified_at": check["last_verified_at"].isoformat()}
                if check["verified_price"] is not None:
                    patch["verified_price"] = check["verified_price"]
                action = check["action"]
                fail = int(deal.get("verify_fail_count") or 0)
                if action == "url_dead":
                    fail += 1; patch["verify_fail_count"] = fail
                    if fail >= MAX_FAIL_COUNT: patch["status"] = "expired"; expired_count += 1
                elif action == "expired":
                    patch["status"] = "expired"; patch["verify_fail_count"] = 0; expired_count += 1
                elif action == "price_changed":
                    patch["status"] = "price_changed"; patch["verify_fail_count"] = 0; changed += 1
                elif action == "price_dropped":
                    # ÎÑ§Ïù¥Î≤Ñ ÏµúÏ†ÄÍ∞Ä < Ïö∞Î¶¨ ÌëúÏãúÍ∞Ä ‚Üí sale_price ÏóÖÎç∞Ïù¥Ìä∏ (Ï†ïÌôïÏÑ± Ïú†ÏßÄ ÌïµÏã¨!)
                    new_price = check["verified_price"]
                    orig = float(deal.get("original_price") or 0)
                    patch["sale_price"] = new_price
                    patch["status"] = "active"
                    patch["verify_fail_count"] = 0
                    if orig > 0 and new_price < orig:
                        patch["discount_rate"] = round((1 - new_price / orig) * 100, 1)
                    ok += 1
                    logger.info(f"    ‚Üì Í∞ÄÍ≤© ÏóÖÎç∞Ïù¥Ìä∏: {int(deal.get('sale_price',0)):,} ‚Üí {int(new_price):,}Ïõê")
                else:
                    patch["status"] = "active"; patch["verify_fail_count"] = 0; ok += 1
                db.update_deal_verify(deal["id"], patch)
            except Exception as e:
                logger.error(f"  Îîú #{deal.get('id')} Í≤ÄÏ¶ù Ïò§Î•ò: {e}")
        logger.info(f"‚úÖ Í∞ÄÍ≤© Í≤ÄÏ¶ù ÏôÑÎ£å ‚Äî Ï†ïÏÉÅ:{ok} Î≥ÄÎèô:{changed} ÎßåÎ£å:{expired_count}")
    except Exception as e:
        logger.error(f"‚ùå Í∞ÄÍ≤© Í≤ÄÏ¶ù Ïò§Î•ò: {e}")


async def _sync_brand_deals():
    """Î∏åÎûúÎìú Í≥µÏãù Ï†ïÍ∞Ä √ó ÎÑ§Ïù¥Î≤Ñ ÌòÑÏû¨Í∞Ä ÎπÑÍµê ‚Üí Ïã§Ï†ú Ìï†Ïù∏ Îîú"""
    try:
        import app.db_supabase as db
        from app.services.brand_deals import collect_brand_deals
        from app.services.deal_validator import validator
        deals_data = await collect_brand_deals(min_discount=10)
        created = skipped = 0
        for item in deals_data:
            if db.deal_url_exists(item["product_url"]):
                continue
            v = validator.validate_sync(item)
            if not v:
                logger.debug(f"[Î∏åÎûúÎìúskip] {v.reason}")
                skipped += 1
                continue
            # Ï†úÎ™©+Í∞ÄÍ≤© Ï§ëÎ≥µ Ï≤¥ÌÅ¨
            if db.deal_duplicate_exists(item["title"], v.sale_price):
                skipped += 1
                continue
            db.create_deal({
                "title": item["title"],
                "description": item.get("description"),
                "original_price": v.original_price,
                "sale_price": v.sale_price,
                "discount_rate": v.discount_rate,
                "image_url": item.get("image_url"),
                "product_url": item["product_url"],
                "source": "naver",
                "category": item.get("category", "Í∏∞ÌÉÄ"),
                "status": "active",
                "is_hot": v.is_hot,
                "submitter_name": item.get("brand", ""),
            })
            created += 1
        logger.info(f"‚úÖ Î∏åÎûúÎìúÎîú sync: {created}Í∞ú Ï†ÄÏû• | {skipped}Í∞ú Ï†úÏô∏")
    except Exception as e:
        logger.error(f"‚ùå Î∏åÎûúÎìúÎîú sync: {e}")


async def _expire_old_deals():
    """3Ïùº Ïù¥ÏÉÅ Îêú Îîú ÏûêÎèô ÎßåÎ£å"""
    try:
        import app.db_supabase as db
        from datetime import datetime, timezone, timedelta
        cutoff = (datetime.now(timezone.utc) - timedelta(days=3)).isoformat()
        sb = db.get_supabase()
        result = sb.table("deals").update({"status": "expired"}).eq("status", "active").lt("created_at", cutoff).execute()
        count = len(result.data) if result.data else 0
        if count:
            logger.info(f"‚úÖ Ïò§ÎûòÎêú Îîú ÎßåÎ£å: {count}Í∞ú")
    except Exception as e:
        logger.error(f"‚ùå Îîú ÎßåÎ£å Ï≤òÎ¶¨ Ïò§Î•ò: {e}")


async def _collect_price_snapshots():
    """ÏùºÏùº Í∞ÄÍ≤© Ïä§ÎÉÖÏÉ∑ (Î∏åÎûúÎìúÎîú 42Ï¢Ö ÌòÑÏû¨Í∞Ä Ï†ÄÏû•)"""
    try:
        from app.services.price_history import collect_daily_snapshots
        saved = await collect_daily_snapshots()
        logger.info(f"[Ïä§ÎÉÖÏÉ∑] {saved}Í∞ú Ï†ÄÏû•")
    except Exception as e:
        logger.error(f"[Ïä§ÎÉÖÏÉ∑] Ïò§Î•ò: {e}")


def start_scheduler():
    """Ïä§ÏºÄÏ§ÑÎü¨ ÏãúÏûë"""
    scheduler.add_job(
        _sync_coupang,
        trigger=IntervalTrigger(minutes=10),
        id="sync_coupang",
        name="Ïø†Ìå° Îîú ÏûêÎèô ÎèôÍ∏∞Ìôî",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_naver,
        trigger=IntervalTrigger(minutes=30),
        id="sync_naver",
        name="ÎÑ§Ïù¥Î≤Ñ Îîú ÏûêÎèô ÎèôÍ∏∞Ìôî",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_ppomppu,
        trigger=IntervalTrigger(minutes=10),
        id="sync_ppomppu",
        name="ÎΩêÎøå Ìï´Îîú ÏûêÎèô ÎèôÍ∏∞Ìôî (ÎπÑÌôúÏÑ±)",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_naver_cafe,
        trigger=IntervalTrigger(minutes=10),
        id="sync_naver_cafe",
        name="Ï†ïÍ∞ÄÍ±∞Î∂Ä Ïπ¥Ìéò Ìï´Îîú ÏàòÏßë (ÎπÑÌôúÏÑ±)",
        replace_existing=True,
    )
    scheduler.add_job(
        _verify_prices,
        trigger=IntervalTrigger(minutes=10),
        id="verify_prices",
        name="Í∞ÄÍ≤© Í≤ÄÏ¶ù (10Î∂ÑÎßàÎã§)",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_brand_deals,
        trigger=IntervalTrigger(hours=2),
        id="sync_brand_deals",
        name="Î∏åÎûúÎìúÎîú Ï†ïÍ∞Ä ÎπÑÍµê ÎèôÍ∏∞Ìôî (2h)",
        replace_existing=True,
    )
    scheduler.add_job(
        _expire_old_deals,
        trigger=IntervalTrigger(hours=6),
        id="expire_old_deals",
        name="Ïò§ÎûòÎêú Îîú ÏûêÎèô ÎßåÎ£å (3Ïùº Ïù¥ÏÉÅ)",
        replace_existing=True,
    )
    scheduler.add_job(
        _collect_price_snapshots,
        trigger=IntervalTrigger(hours=24),
        id="price_snapshots",
        name="ÏùºÏùº Í∞ÄÍ≤© Ïä§ÎÉÖÏÉ∑ (Î∏åÎûúÎìúÎîú 42Ï¢Ö)",
        replace_existing=True,
    )
    scheduler.start()
    msg = "üïê Ïä§ÏºÄÏ§ÑÎü¨ ÏãúÏûë: Ïø†Ìå°(30Î∂Ñ) / ÎÑ§Ïù¥Î≤Ñ(1h) / ÎΩêÎøå(30Î∂Ñ) / Í∞ÄÍ≤©Í≤ÄÏ¶ù(1h) / ÎßåÎ£åÏ≤òÎ¶¨(6h)"
    logger.info(msg)
    print(msg, flush=True)  # uvicorn stdoutÏóêÎèÑ Ï∂úÎ†•


def stop_scheduler():
    if scheduler.running:
        scheduler.shutdown()
        logger.info("üõë Ïä§ÏºÄÏ§ÑÎü¨ Ï¢ÖÎ£å")
