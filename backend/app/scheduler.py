"""
APScheduler ë°±ê·¸ë¼ìš´ë“œ ìë™ ì‘ì—…
- ë§¤ 10ë¶„  : ì¿ íŒ¡ ë”œ sync + ê°€ê²© ê²€ì¦
- ë§¤ 1ì‹œê°„ : ë„¤ì´ë²„ ë”œ sync
- ë§¤ 1ì‹œê°„ : ê°€ê²© ê²€ì¦ (ë“±ë¡ëœ ë”œ í˜„ì¬ ê°€ê²© ì²´í¬ â†’ ê°€ê²© ì˜¤ë¥´ë©´ ìë™ ë¹„í™œì„±)
"""
import asyncio
import logging
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger

logger = logging.getLogger(__name__)

scheduler = AsyncIOScheduler()


async def _sync_coupang():
    # ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ API ìŠ¹ì¸ ì „ê¹Œì§€ ë¹„í™œì„±í™”
    # ìƒ˜í”Œ ë°ì´í„°(link.coupang.com/sample)ëŠ” ì´ë¯¸ì§€ ì—†ê³  ë§í¬ ë¶ˆí†µ â†’ ì‚¬ìš©ì ê²½í—˜ ìµœì•…
    # íŒŒíŠ¸ë„ˆìŠ¤ ìŠ¹ì¸ í›„ partners.coupang.comì—ì„œ API í‚¤ ë°›ì•„ í™œì„±í™”
    logger.info("â¸ ì¿ íŒ¡ sync ë¹„í™œì„±í™” (íŒŒíŠ¸ë„ˆìŠ¤ ìŠ¹ì¸ ëŒ€ê¸° ì¤‘)")
    return


async def _sync_naver():
    try:
        import app.db_supabase as db
        from app.services.naver import collect_real_deals
        from app.services.deal_validator import validator
        deals_data = await collect_real_deals(limit_per_keyword=5)
        created = skipped = 0
        for item in deals_data:
            if db.deal_url_exists(item["product_url"]):
                continue
            v = validator.validate_sync(item)
            if not v:
                logger.debug(f"[ë„¤ì´ë²„skip] {v.reason}")
                skipped += 1
                continue
            # ì œëª©+ê°€ê²© ì¤‘ë³µ ì²´í¬ (URL ë‹¬ë¼ë„ ë™ì¼ ì œí’ˆ ë°©ì§€)
            if db.deal_duplicate_exists(item["title"], v.sale_price):
                skipped += 1
                continue
            db.create_deal({
                "title": item["title"],
                "original_price": v.original_price,
                "sale_price": v.sale_price,
                "discount_rate": v.discount_rate,
                "image_url": item.get("image_url"),
                "product_url": item["product_url"],
                "source": "naver",
                "category": item.get("category", "ê¸°íƒ€"),
                "status": "active",
                "is_hot": v.is_hot,
            })
            created += 1
        logger.info(f"âœ… ë„¤ì´ë²„ sync: {created}ê°œ ì €ì¥ | {skipped}ê°œ ì œì™¸")
    except Exception as e:
        logger.error(f"âŒ ë„¤ì´ë²„ sync: {e}")


async def _sync_ppomppu():
    """
    ë½ë¿Œ í•«ë”œ ìˆ˜ì§‘ â€” Playwright ì‹¤ì‹œê°„ ê°€ê²© ê²€ì¦

    íŒŒì´í”„ë¼ì¸:
    1. RSS íŒŒì‹± â†’ ì œëª©/ê°€ê²©/ppomppu í¬ìŠ¤íŠ¸ URL
    2. ê° í¬ìŠ¤íŠ¸ Playwright ë Œë”ë§ â†’ ì‹¤ì œ ì‡¼í•‘ëª° URL ì¶”ì¶œ
    3. ì‹¤ì œ ì‡¼í•‘ëª° í˜„ì¬ê°€ í¬ë¡¤ë§
    4. ì»¤ë®¤ë‹ˆí‹° ì œì‹œê°€ vs ì‹¤ì œê°€ ë¹„êµ (Â±10%) â†’ ë¶ˆì¼ì¹˜ë©´ ìŠ¤í‚µ
    5. í†µê³¼í•œ ë”œë§Œ ì‹¤ì œ ì‡¼í•‘ëª° URLë¡œ ì €ì¥
    """
    try:
        import app.db_supabase as db
        from app.services.ppomppu import fetch_ppomppu_deals
        from app.services.price_scrapers.playwright_scraper import (
            fetch_retailer_url_from_ppomppu, get_actual_price
        )
        from playwright.async_api import async_playwright

        deals_data = await fetch_ppomppu_deals()
        created = skipped = 0
        PRICE_TOLERANCE = 0.10  # 10% ì˜¤ì°¨ í—ˆìš©

        async with async_playwright() as pw:
            browser = await pw.chromium.launch(
                headless=True,
                args=["--no-sandbox", "--disable-dev-shm-usage", "--disable-gpu",
                      "--disable-blink-features=AutomationControlled"],
            )
            ctx = await browser.new_context(
                user_agent=(
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
                ),
                locale="ko-KR",
                viewport={"width": 1280, "height": 800},
            )
            page = await ctx.new_page()
            await page.add_init_script(
                "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
            )

            for item in deals_data:
                sale = float(item.get("sale_price") or 0)
                is_free = sale == 0
                # fetch_ppomppu_deals()ëŠ” "source_post_url" í‚¤ë¡œ ë½ë¿Œ URL ë°˜í™˜
                ppomppu_url = item.get("source_post_url") or item.get("ppomppu_url") or ""

                # ì´ë¯¸ ìˆ˜ì§‘ëœ í¬ìŠ¤íŠ¸ ìŠ¤í‚µ
                if ppomppu_url and db.deal_url_exists(ppomppu_url):
                    skipped += 1
                    continue

                # â”€â”€ ë¬´ë£Œë”œ (ê°€ê²© ê²€ì¦ ë¶ˆí•„ìš”) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if is_free and ppomppu_url:
                    if not db.deal_url_exists(ppomppu_url):
                        db.create_deal({
                            "title": item["title"],
                            "original_price": 0,
                            "sale_price": 0,
                            "discount_rate": 100,
                            "image_url": item.get("image_url"),
                            "product_url": ppomppu_url,
                            "source": "community",
                            "category": item.get("category", "ê¸°íƒ€"),
                            "status": "active",
                            "is_hot": False,
                            "submitter_name": item.get("submitter_name", "ë½ë¿Œ"),
                        })
                        created += 1
                    continue

                if sale <= 0 or not ppomppu_url:
                    skipped += 1
                    continue

                # â”€â”€ ì‹¤ì œ ì‡¼í•‘ëª° URL ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                from app.services.price_scrapers.playwright_scraper import PPOMPPU_ENDED_SENTINEL
                retailer_url = await fetch_retailer_url_from_ppomppu(ppomppu_url, playwright_page=page)
                if retailer_url == PPOMPPU_ENDED_SENTINEL:
                    logger.info(f"[ë½ë¿Œí’ˆì ˆ] ì¢…ê²°ëœ ê²Œì‹œë¬¼ ìŠ¤í‚µ: {item['title'][:40]}")
                    skipped += 1
                    continue
                if not retailer_url:
                    logger.debug(f"[ë½ë¿Œskip] ì‡¼í•‘ëª° URL ì—†ìŒ: {item['title'][:40]}")
                    skipped += 1
                    continue

                if db.deal_url_exists(retailer_url):
                    skipped += 1
                    continue

                # â”€â”€ ì‹¤ì œ í˜„ì¬ê°€ í¬ë¡¤ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                actual = await get_actual_price(retailer_url, playwright_page=page)

                if actual is None:
                    # í¬ë¡¤ë§ ì‹¤íŒ¨ â†’ ìˆ˜ì§‘ ìŠ¤í‚µ (ì‹ ë¢° ë¶ˆê°€)
                    logger.debug(f"[ë½ë¿Œskip] ê°€ê²© í¬ë¡¤ë§ ì‹¤íŒ¨: {item['title'][:40]}")
                    skipped += 1
                    continue

                if not actual.in_stock:
                    logger.debug(f"[ë½ë¿Œskip] í’ˆì ˆ: {item['title'][:40]}")
                    skipped += 1
                    continue

                # â”€â”€ ê°€ê²© ì¼ì¹˜ ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                price_diff = abs(actual.price - sale) / sale
                if price_diff > PRICE_TOLERANCE:
                    logger.info(
                        f"[ë½ë¿Œskip] ê°€ê²© ë¶ˆì¼ì¹˜: ì œì‹œ={sale:,.0f} ì‹¤ì œ={actual.price:,.0f} "
                        f"({price_diff*100:.0f}%) | {item['title'][:35]}"
                    )
                    skipped += 1
                    continue

                # â”€â”€ ì¤‘ë³µ ì²´í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if db.deal_duplicate_exists(item["title"], sale):
                    skipped += 1
                    continue

                # â”€â”€ í• ì¸ìœ¨ ê³„ì‚° (ì‹¤ì œê°€ ê¸°ì¤€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                orig = float(item.get("original_price") or 0)
                if orig <= 0 or orig <= sale:
                    skipped += 1
                    continue
                discount_rate = round((1 - sale / orig) * 100, 1)
                if discount_rate < 10:
                    skipped += 1
                    continue

                db.create_deal({
                    "title": item["title"],
                    "description": item.get("description"),
                    "original_price": orig,
                    "sale_price": sale,
                    "discount_rate": discount_rate,
                    "image_url": item.get("image_url"),
                    "product_url": retailer_url,           # ì‹¤ì œ ì‡¼í•‘ëª° URL
                    "source_post_url": item.get("source_post_url") or ppomppu_url,  # ì›ê¸€ URL (ë§Œë£Œ ê°ì§€)
                    "source": "community",
                    "category": item.get("category", "ê¸°íƒ€"),
                    "status": "active",
                    "is_hot": discount_rate >= 20,
                    "submitter_name": item.get("submitter_name", "ë½ë¿Œ"),
                    "admin_note": f"ì‹¤ì œê°€ ê²€ì¦: {actual.price:,}ì› ({actual.retailer})",
                })
                logger.info(
                    f"  âœ… ì €ì¥: {item['title'][:35]} | -{discount_rate}% | "
                    f"ì‹¤ì œê°€={actual.price:,}ì›"
                )
                created += 1

            await browser.close()

        logger.info(f"âœ… ë½ë¿Œ sync: {created}ê°œ ì €ì¥ | {skipped}ê°œ ì œì™¸")
    except Exception as e:
        logger.error(f"âŒ ë½ë¿Œ sync: {e}")


async def _sync_naver_cafe():
    # â›” ì˜êµ¬ ë¹„í™œì„±í™” â€” ì»¤ë®¤ë‹ˆí‹° ë”œ ì‹ ë¢°ì„± ë¬¸ì œ
    logger.info("â›” ì •ê°€ê±°ë¶€ ì¹´í˜ sync ë¹„í™œì„±í™”")
    return
    try:
        import app.db_supabase as db
        from app.services.naver_cafe import fetch_naver_cafe_deals

        deals_data = await fetch_naver_cafe_deals()
        created = skipped = 0

        from app.services.price_scrapers import check_community_deal_price
        from app.config import settings

        async with __import__("httpx").AsyncClient(timeout=8) as client:
            for item in deals_data:
                if db.deal_url_exists(item.get("product_url", "")):
                    skipped += 1
                    continue
                if db.deal_duplicate_exists(item["title"], item.get("sale_price", 0)):
                    skipped += 1
                    continue

                # naver_cafeëŠ” ì´ë¯¸ naver ê²€ìƒ‰ ì™„ë£Œ â†’ ë”œ ì†Œì§„ ì—¬ë¶€ë§Œ ì¬í™•ì¸
                price_check = await check_community_deal_price(
                    title=item["title"],
                    community_price=float(item.get("sale_price") or 0),
                    naver_client_id=settings.NAVER_CLIENT_ID,
                    naver_client_secret=settings.NAVER_CLIENT_SECRET,
                    client=client,
                )
                if not price_check:
                    logger.debug(f"[ì¹´í˜skip] {price_check.reason} | {item['title'][:40]}")
                    skipped += 1
                    continue

                db.create_deal({
                    "title": item["title"],
                    "description": item.get("description"),
                    "original_price": price_check.naver_hprice or price_check.naver_lprice,
                    "sale_price": price_check.community_price,
                    "discount_rate": price_check.discount_vs_hprice,
                    "image_url": item.get("image_url") or price_check.image_url,
                    "product_url": price_check.naver_product_url or item.get("product_url"),
                    "source": "community",
                    "category": item.get("category", "ê¸°íƒ€"),
                    "status": "active",
                    "is_hot": price_check.discount_vs_hprice >= 20,
                    "submitter_name": item.get("submitter_name", "ì •ê°€ê±°ë¶€"),
                    "admin_note": f"ì‹¤ì‹œê°„ ê²€ì¦: lprice={price_check.naver_lprice:,.0f}ì›",
                })
                created += 1

        logger.info(f"âœ… ì •ê°€ê±°ë¶€ ì¹´í˜: {created}ê°œ ì‹ ê·œ | {skipped}ê°œ ìŠ¤í‚µ")
    except Exception as e:
        logger.error(f"âŒ ì •ê°€ê±°ë¶€ ì¹´í˜ sync: {e}")


async def _verify_prices():
    logger.info("ğŸ” ê°€ê²© ê²€ì¦ ì‹œì‘...")
    try:
        import app.db_supabase as db
        from app.services.price_checker import verify_deal, MAX_FAIL_COUNT
        from datetime import datetime, timedelta
        cutoff = (datetime.utcnow() - timedelta(minutes=8)).isoformat()
        deals = db.get_deals_for_verify(cutoff)
        logger.info(f"  ê²€ì¦ ëŒ€ìƒ: {len(deals)}ê°œ")
        from app.services.price_scrapers import RealtimePriceChecker
        from app.config import settings
        rt_checker = RealtimePriceChecker(settings.NAVER_CLIENT_ID, settings.NAVER_CLIENT_SECRET)

        ok = changed = expired_count = 0
        async with __import__("httpx").AsyncClient(timeout=8) as hclient:
          for deal in deals:
            try:
                # ì»¤ë®¤ë‹ˆí‹° ë”œ: í•«ë”œ ì†Œì§„ ì—¬ë¶€ ì‹¤ì‹œê°„ ì¬í™•ì¸
                if deal.get("source") == "community" and deal.get("sale_price"):
                    rt = await rt_checker.recheck_existing(
                        title=deal["title"],
                        stored_sale_price=float(deal["sale_price"]),
                        client=hclient,
                    )
                    if rt["action"] == "expired":
                        logger.info(f"  ğŸ›‘ ì»¤ë®¤ë‹ˆí‹° ë”œ ì†Œì§„: {deal['title'][:40]} | {rt['reason']}")
                        db.update_deal_verify(deal["id"], {"status": "expired", "verify_fail_count": 0})
                        expired_count += 1
                        continue

                check = await verify_deal(deal)
                patch = {"last_verified_at": check["last_verified_at"].isoformat()}
                if check["verified_price"] is not None:
                    patch["verified_price"] = check["verified_price"]
                action = check["action"]
                fail = int(deal.get("verify_fail_count") or 0)
                if action == "url_dead":
                    fail += 1; patch["verify_fail_count"] = fail
                    if fail >= MAX_FAIL_COUNT: patch["status"] = "expired"; expired_count += 1
                elif action == "expired":
                    patch["status"] = "expired"; patch["verify_fail_count"] = 0; expired_count += 1
                elif action == "price_changed":
                    new_price = check.get("verified_price")
                    orig = float(deal.get("original_price") or 0)
                    # ì»¤ë®¤ë‹ˆí‹° ë”œì€ orig=0ì´ë¯€ë¡œ ê°€ê²©ë³€ë™ ë§Œë£Œ íŒë‹¨ ë¶ˆê°€ â†’ ì›ê¸€ ë§Œë£Œ ê°ì§€ì— ë§¡ê¹€
                    if deal.get("source") == "community" or orig <= 0:
                        patch["status"] = "active"  # ê·¸ëƒ¥ ìœ ì§€
                        patch["verify_fail_count"] = 0
                        ok += 1
                    # í˜„ì¬ê°€ê°€ ì •ê°€ì˜ 90% ì´ìƒ = í• ì¸ìœ¨ 10% ë¯¸ë§Œ â†’ ì™„ì „ ë§Œë£Œ
                    elif new_price and new_price >= orig * 0.90:
                        patch["status"] = "expired"
                        patch["verify_fail_count"] = 0
                        expired_count += 1
                        dr_now = round((1 - new_price / orig) * 100, 1)
                        logger.info(
                            f"  ğŸ›‘ í• ì¸ ì†Œë©¸ ë§Œë£Œ: {deal.get('title','')[:40]} "
                            f"| í˜„ì¬í• ì¸={dr_now}%"
                        )
                    else:
                        patch["status"] = "price_changed"
                        patch["verify_fail_count"] = 0
                        changed += 1
                elif action == "price_dropped":
                    # ë„¤ì´ë²„ ìµœì €ê°€ < ìš°ë¦¬ í‘œì‹œê°€ â†’ sale_price ì—…ë°ì´íŠ¸ (ì •í™•ì„± ìœ ì§€ í•µì‹¬!)
                    new_price = check["verified_price"]
                    orig = float(deal.get("original_price") or 0)
                    patch["sale_price"] = new_price
                    patch["status"] = "active"
                    patch["verify_fail_count"] = 0
                    if orig > 0 and new_price < orig:
                        patch["discount_rate"] = round((1 - new_price / orig) * 100, 1)
                    ok += 1
                    logger.info(f"    â†“ ê°€ê²© ì—…ë°ì´íŠ¸: {int(deal.get('sale_price',0)):,} â†’ {int(new_price):,}ì›")
                else:
                    patch["status"] = "active"; patch["verify_fail_count"] = 0; ok += 1
                # ê°€ê²© ë¡œê·¸ insert (ì—ëŸ¬ ë¬´ì‹œ)
                current_price = check.get("verified_price")
                if current_price is not None:
                    try:
                        db.get_supabase().table("deal_price_log").insert({
                            "deal_id": deal["id"],
                            "price": int(current_price),
                            "source": "verify"
                        }).execute()
                    except Exception:
                        pass
                db.update_deal_verify(deal["id"], patch)
            except Exception as e:
                logger.error(f"  ë”œ #{deal.get('id')} ê²€ì¦ ì˜¤ë¥˜: {e}")
        logger.info(f"âœ… ê°€ê²© ê²€ì¦ ì™„ë£Œ â€” ì •ìƒ:{ok} ë³€ë™:{changed} ë§Œë£Œ:{expired_count}")
    except Exception as e:
        logger.error(f"âŒ ê°€ê²© ê²€ì¦ ì˜¤ë¥˜: {e}")


async def _sync_brand_deals():
    """ë¸Œëœë“œ ê³µì‹ ì •ê°€ Ã— ë„¤ì´ë²„ í˜„ì¬ê°€ ë¹„êµ â†’ ì‹¤ì œ í• ì¸ ë”œ"""
    try:
        import app.db_supabase as db
        from app.services.brand_deals import collect_brand_deals
        from app.services.deal_validator import validator
        deals_data = await collect_brand_deals(min_discount=10)
        created = skipped = 0
        for item in deals_data:
            if db.deal_url_exists(item["product_url"]):
                continue
            v = validator.validate_sync(item)
            if not v:
                logger.debug(f"[ë¸Œëœë“œskip] {v.reason}")
                skipped += 1
                continue
            # ì œëª©+ê°€ê²© ì¤‘ë³µ ì²´í¬
            if db.deal_duplicate_exists(item["title"], v.sale_price):
                skipped += 1
                continue
            db.create_deal({
                "title": item["title"],
                "description": item.get("description"),
                "original_price": v.original_price,
                "sale_price": v.sale_price,
                "discount_rate": v.discount_rate,
                "image_url": item.get("image_url"),
                "product_url": item["product_url"],
                "source": "naver",
                "category": item.get("category", "ê¸°íƒ€"),
                "status": "active",
                "is_hot": v.is_hot,
                "submitter_name": item.get("brand", ""),
            })
            created += 1
        logger.info(f"âœ… ë¸Œëœë“œë”œ sync: {created}ê°œ ì €ì¥ | {skipped}ê°œ ì œì™¸")
    except Exception as e:
        logger.error(f"âŒ ë¸Œëœë“œë”œ sync: {e}")


async def _expire_old_deals():
    """3ì¼ ì´ìƒ ëœ ë”œ ìë™ ë§Œë£Œ"""
    try:
        import app.db_supabase as db
        from datetime import datetime, timezone, timedelta
        cutoff = (datetime.now(timezone.utc) - timedelta(days=3)).isoformat()
        sb = db.get_supabase()
        result = sb.table("deals").update({"status": "expired"}).eq("status", "active").lt("created_at", cutoff).execute()
        count = len(result.data) if result.data else 0
        if count:
            logger.info(f"âœ… ì˜¤ë˜ëœ ë”œ ë§Œë£Œ: {count}ê°œ")
    except Exception as e:
        logger.error(f"âŒ ë”œ ë§Œë£Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")


async def _sync_clien():
    """í´ë¦¬ì•™ í•«ë”œ RSS ìˆ˜ì§‘ â€” 2ì‹œê°„ë§ˆë‹¤"""
    try:
        import app.db_supabase as db
        from app.services.clien import fetch_clien_deals

        deals_data = await fetch_clien_deals()
        created = skipped = 0

        for item in deals_data:
            source_post_url = item.get("source_post_url", "")

            # ì´ë¯¸ ìˆ˜ì§‘ëœ ì›ê¸€ ìŠ¤í‚µ
            if source_post_url and db.deal_url_exists(source_post_url):
                skipped += 1
                continue

            product_url = item.get("product_url", "")
            if product_url and db.deal_url_exists(product_url):
                skipped += 1
                continue

            sale = float(item.get("sale_price") or 0)
            is_free = sale == 0

            if is_free and source_post_url:
                db.create_deal({
                    "title": item["title"],
                    "original_price": 0,
                    "sale_price": 0,
                    "discount_rate": 100,
                    "image_url": item.get("image_url"),
                    "product_url": source_post_url,
                    "source_post_url": source_post_url,
                    "source": "community",
                    "category": item.get("category", "ê¸°íƒ€"),
                    "status": "active",
                    "is_hot": False,
                    "submitter_name": item.get("submitter_name", "í´ë¦¬ì•™"),
                    "description": item.get("description"),
                })
                created += 1
                continue

            if sale <= 0:
                skipped += 1
                continue

            orig = float(item.get("original_price") or 0)
            discount_rate = float(item.get("discount_rate") or 0)

            if orig <= 0 or orig <= sale:
                skipped += 1
                continue
            if discount_rate < 10:
                skipped += 1
                continue

            if db.deal_duplicate_exists(item["title"], sale):
                skipped += 1
                continue

            db.create_deal({
                "title": item["title"],
                "description": item.get("description"),
                "original_price": orig,
                "sale_price": sale,
                "discount_rate": discount_rate,
                "image_url": item.get("image_url"),
                "product_url": product_url or source_post_url,
                "source_post_url": source_post_url,
                "source": "community",
                "category": item.get("category", "ê¸°íƒ€"),
                "status": "active",
                "is_hot": discount_rate >= 20,
                "submitter_name": item.get("submitter_name", "í´ë¦¬ì•™"),
            })
            logger.info(f"  âœ… [í´ë¦¬ì•™] ì €ì¥: {item['title'][:35]} | -{discount_rate}%")
            created += 1

        logger.info(f"âœ… í´ë¦¬ì•™ sync: {created}ê°œ ì €ì¥ | {skipped}ê°œ ì œì™¸")
    except Exception as e:
        logger.error(f"âŒ í´ë¦¬ì•™ sync: {e}")


async def _sync_algumon():
    """ì•Œêµ¬ëª¬ APIë¡œ ì»¤ë®¤ë‹ˆí‹° ë”œ ìˆ˜ì§‘ (ë½ë¿Œ+ë£¨ë¦¬ì›¹+ì–´ë¯¸ìƒˆ+ì•„ì¹´ë¼ì´ë¸Œ)"""
    try:
        import app.db_supabase as db
        from app.services.algumon import fetch_algumon_deals, fetch_ruliweb_deals, process_algumon_deals
        from app.services.categorizer import infer_category

        # ìµœê·¼ ë“±ë¡ëœ ì»¤ë®¤ë‹ˆí‹° ë”œ URL ëª©ë¡ (ì¤‘ë³µ ë°©ì§€)
        sb = db.get_supabase()
        recent = sb.table("deals").select("product_url").eq("source", "community").limit(300).execute()
        existing_urls = {r["product_url"] for r in (recent.data or []) if r.get("product_url")}

        # ì•Œêµ¬ëª¬ 5í˜ì´ì§€ (50ê°œ) + ë£¨ë¦¬ì›¹ RSS ë³‘ë ¬ ìˆ˜ì§‘
        algumon_raw, ruliweb_raw = await asyncio.gather(
            fetch_algumon_deals(pages=5),
            fetch_ruliweb_deals(),
            return_exceptions=True,
        )
        raw = []
        if isinstance(algumon_raw, list): raw.extend(algumon_raw)
        if isinstance(ruliweb_raw, list): raw.extend(ruliweb_raw)

        if not raw:
            return

        logger.info(f"[ì•Œêµ¬ëª¬] ì›ë³¸ {len(raw)}ê°œ ìˆ˜ì§‘")
        processed = await process_algumon_deals(raw, existing_urls)
        logger.info(f"[ì•Œêµ¬ëª¬] í•„í„° í†µê³¼ {len(processed)}ê°œ")

        saved = 0
        for deal_data in processed:
            try:
                # ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
                if not deal_data.get("category") or deal_data["category"] == "ê¸°íƒ€":
                    deal_data["category"] = infer_category(deal_data["title"])

                db.create_deal({
                    "title": deal_data["title"],
                    "sale_price": deal_data["sale_price"],
                    "original_price": deal_data["original_price"],
                    "discount_rate": deal_data["discount_rate"],
                    "product_url": deal_data["product_url"],
                    "source_post_url": deal_data.get("source_post_url"),
                    "image_url": deal_data.get("image_url", ""),
                    "source": "community",
                    "category": deal_data["category"],
                    "description": deal_data.get("description", ""),
                })
                saved += 1
            except ValueError as e:
                logger.debug(f"[ì•Œêµ¬ëª¬] ë“±ë¡ ê±°ë¶€: {e}")
            except Exception as e:
                if "duplicate" not in str(e).lower() and "unique" not in str(e).lower():
                    logger.warning(f"[ì•Œêµ¬ëª¬] ë“±ë¡ ì˜¤ë¥˜: {e}")

        if saved:
            logger.info(f"âœ… ì•Œêµ¬ëª¬ {saved}ê°œ ë“±ë¡ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"âŒ ì•Œêµ¬ëª¬ ë™ê¸°í™” ì˜¤ë¥˜: {e}")


async def _check_community_deal_expiry():
    """ëª¨ë“  ë”œ ì›ê¸€ ë§Œë£Œ ê°ì§€ â†’ ìë™ expired ì²˜ë¦¬ (source ë¬´ê´€, source_post_url ìˆëŠ” ê²ƒ ì „ì²´)"""
    try:
        import app.db_supabase as db
        from app.services.community_enricher import check_deal_expired_from_url
        import asyncio

        # ë“±ë¡ í›„ 1ì‹œê°„ ì´ìƒ ëœ í™œì„± ë”œ ì „ì²´ ì²´í¬ (source_post_url ìˆëŠ” ê²ƒ)
        deals = db.get_community_deals_for_expiry_check(hours_since_created=1)
        if not deals:
            return

        logger.info(f"[ì›ê¸€ ë§Œë£Œì²´í¬] {len(deals)}ê°œ ë”œ í™•ì¸ ì‹œì‘")
        expired_count = 0

        async def check_one(deal):
            nonlocal expired_count
            url = deal.get("source_post_url", "")
            if not url:
                return
            is_expired, reason = await check_deal_expired_from_url(url)
            if is_expired:
                db.expire_deal(deal["id"])
                # admin_note ì—…ë°ì´íŠ¸
                db.get_supabase().table("deals").update({
                    "admin_note": f"[ìë™ë§Œë£Œ] ì›ê¸€ ì¢…ë£Œ ê°ì§€: {reason}"
                }).eq("id", deal["id"]).execute()
                expired_count += 1
                logger.info(f"  âœ… ë§Œë£Œì²˜ë¦¬: {deal['title'][:30]} ({reason})")

        # ë™ì‹œì— ìµœëŒ€ 5ê°œì”© ì²´í¬ (ê³¼ë„í•œ ìš”ì²­ ë°©ì§€)
        for i in range(0, len(deals), 5):
            batch = deals[i:i+5]
            await asyncio.gather(*[check_one(d) for d in batch])
            await asyncio.sleep(1)

        if expired_count:
            logger.info(f"[ì»¤ë®¤ë‹ˆí‹° ë§Œë£Œì²´í¬] ì™„ë£Œ: {expired_count}/{len(deals)}ê°œ ë§Œë£Œ")

    except Exception as e:
        logger.error(f"âŒ ì»¤ë®¤ë‹ˆí‹° ë§Œë£Œì²´í¬ ì˜¤ë¥˜: {e}")


async def _collect_price_snapshots():
    """ì¼ì¼ ê°€ê²© ìŠ¤ëƒ…ìƒ· (ë¸Œëœë“œë”œ 42ì¢… í˜„ì¬ê°€ ì €ì¥)"""
    try:
        from app.services.price_history import collect_daily_snapshots
        saved = await collect_daily_snapshots()
        logger.info(f"[ìŠ¤ëƒ…ìƒ·] {saved}ê°œ ì €ì¥")
    except Exception as e:
        logger.error(f"[ìŠ¤ëƒ…ìƒ·] ì˜¤ë¥˜: {e}")


async def _run_watchlist_monitor():
    """ì¸ê¸° ì œí’ˆ ì›Œì¹˜ë¦¬ìŠ¤íŠ¸ ê°€ê²© ëª¨ë‹ˆí„°ë§ â€” 30ë¶„ë§ˆë‹¤"""
    try:
        from app.services.watchlist_monitor import run_watchlist_monitor
        await run_watchlist_monitor()
    except Exception as e:
        logger.error(f"âŒ ì›Œì¹˜ë¦¬ìŠ¤íŠ¸ ëª¨ë‹ˆí„° ì˜¤ë¥˜: {e}")


async def _run_kream_sync():
    """KREAM íŠ¸ë Œë”© â†’ ì›Œì¹˜ë¦¬ìŠ¤íŠ¸ ê°±ì‹  â€” ì£¼ 1íšŒ"""
    try:
        from app.services.watchlist_monitor import run_kream_sync
        await run_kream_sync()
    except Exception as e:
        logger.error(f"âŒ KREAM ë™ê¸°í™” ì˜¤ë¥˜: {e}")


def start_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    # ì² ì¹™ ìœ„ë°˜ ë”œ ìë™ ë§Œë£Œ (5ë¶„ë§ˆë‹¤)
    scheduler.add_job(
        _cleanup_invalid_deals,
        trigger=IntervalTrigger(minutes=5),
        id="cleanup_invalid",
        max_instances=1,
    )

    scheduler.add_job(
        _sync_coupang,
        trigger=IntervalTrigger(minutes=10),
        id="sync_coupang",
        name="ì¿ íŒ¡ ë”œ ìë™ ë™ê¸°í™”",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_naver,
        trigger=IntervalTrigger(minutes=30),
        id="sync_naver",
        name="ë„¤ì´ë²„ ë”œ ìë™ ë™ê¸°í™”",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_ppomppu,
        trigger=IntervalTrigger(minutes=10),
        id="sync_ppomppu",
        name="ë½ë¿Œ í•«ë”œ ìë™ ë™ê¸°í™” (ë¹„í™œì„±)",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_naver_cafe,
        trigger=IntervalTrigger(minutes=10),
        id="sync_naver_cafe",
        name="ì •ê°€ê±°ë¶€ ì¹´í˜ í•«ë”œ ìˆ˜ì§‘ (ë¹„í™œì„±)",
        replace_existing=True,
    )
    scheduler.add_job(
        _verify_prices,
        trigger=IntervalTrigger(minutes=10),
        id="verify_prices",
        name="ê°€ê²© ê²€ì¦ (10ë¶„ë§ˆë‹¤)",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_brand_deals,
        trigger=IntervalTrigger(hours=2),
        id="sync_brand_deals",
        name="ë¸Œëœë“œë”œ ì •ê°€ ë¹„êµ ë™ê¸°í™” (2h)",
        replace_existing=True,
    )
    scheduler.add_job(
        _expire_old_deals,
        trigger=IntervalTrigger(hours=6),
        id="expire_old_deals",
        name="ì˜¤ë˜ëœ ë”œ ìë™ ë§Œë£Œ (3ì¼ ì´ìƒ)",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_clien,
        trigger=IntervalTrigger(hours=2),
        id="sync_clien",
        name="í´ë¦¬ì•™ í•«ë”œ RSS ë™ê¸°í™” (2h)",
        replace_existing=True,
    )
    scheduler.add_job(
        _sync_algumon,
        trigger=IntervalTrigger(minutes=20),
        id="sync_algumon",
        name="ì•Œêµ¬ëª¬ ì»¤ë®¤ë‹ˆí‹° ë”œ ë™ê¸°í™” (20m)",
        replace_existing=True,
    )
    scheduler.add_job(
        _check_community_deal_expiry,
        trigger=IntervalTrigger(minutes=10),
        id="community_expiry_check",
        name="ì›ê¸€ ë§Œë£Œ ìë™ ê°ì§€ â€” ì „ì²´ ë”œ (10m)",
        replace_existing=True,
    )
    scheduler.add_job(
        _collect_price_snapshots,
        trigger=IntervalTrigger(hours=24),
        id="price_snapshots",
        name="ì¼ì¼ ê°€ê²© ìŠ¤ëƒ…ìƒ· (ë¸Œëœë“œë”œ 42ì¢…)",
        replace_existing=True,
    )
    scheduler.add_job(
        _run_watchlist_monitor,
        trigger=IntervalTrigger(minutes=30),
        id="watchlist_monitor",
        name="ì¸ê¸° ì œí’ˆ ì›Œì¹˜ë¦¬ìŠ¤íŠ¸ ê°€ê²© ëª¨ë‹ˆí„°ë§ (30ë¶„)",
        replace_existing=True,
    )
    scheduler.add_job(
        _run_kream_sync,
        trigger=IntervalTrigger(weeks=1),
        id="kream_sync",
        name="KREAM íŠ¸ë Œë”© ì›Œì¹˜ë¦¬ìŠ¤íŠ¸ ê°±ì‹  (ì£¼ 1íšŒ)",
        replace_existing=True,
    )
    scheduler.start()
    msg = "ğŸ• ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘: ì›Œì¹˜ë¦¬ìŠ¤íŠ¸(30ë¶„) / ì¿ íŒ¡(30ë¶„) / ë„¤ì´ë²„(1h) / ë½ë¿Œ(30ë¶„) / ê°€ê²©ê²€ì¦(1h) / ë§Œë£Œì²˜ë¦¬(6h)"
    logger.info(msg)
    print(msg, flush=True)  # uvicorn stdoutì—ë„ ì¶œë ¥


def stop_scheduler():
    if scheduler.running:
        scheduler.shutdown()
        logger.info("ğŸ›‘ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ")


async def _cleanup_invalid_deals():
    """5ë¶„ë§ˆë‹¤: í• ì¸ìœ¨ 0% or ì‹í’ˆ/ì¼ìƒìš©í’ˆ ì»¤ë®¤ë‹ˆí‹° ë”œ ìë™ ë§Œë£Œ"""
    try:
        import app.db_supabase as db
        sb = db.get_supabase()

        # 1) í• ì¸ìœ¨ 0% active ë”œ â€” ì»¤ë®¤ë‹ˆí‹° ë”œì€ ì œì™¸ (MSRP ì—†ì´ ë“±ë¡í•˜ëŠ” ë°©ì‹)
        res = sb.table("deals").select("id,title,discount_rate,category,source") \
            .eq("status", "active") \
            .eq("discount_rate", 0) \
            .neq("source", "community") \
            .execute()
        for d in (res.data or []):
            # ë¬´ë£Œë”œ(sale_price=0)ì€ ì˜ˆì™¸
            sale_res = sb.table("deals").select("sale_price").eq("id", d["id"]).limit(1).execute()
            sale = float((sale_res.data or [{}])[0].get("sale_price", 1) or 1)
            if sale > 0:  # ìœ ë£Œë”œì¸ë° í• ì¸ìœ¨ 0 â†’ ë§Œë£Œ
                sb.table("deals").update({
                    "status": "expired",
                    "admin_note": "[ìë™ë§Œë£Œ] í• ì¸ìœ¨ 0%"
                }).eq("id", d["id"]).execute()
                logger.info(f"ğŸ—‘ ìë™ë§Œë£Œ(0%): #{d['id']} {d['title'][:35]}")

        # 2) ì‹í’ˆ/ì¼ìƒìš©í’ˆ ì»¤ë®¤ë‹ˆí‹° ë”œ â€” ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ + íƒ€ì´í‹€ í‚¤ì›Œë“œ 2ì¤‘ ê²€ì‚¬
        from app.services.community_enricher import is_food_or_daily
        BLOCKED_CATS = ["ì‹í’ˆ", "ìœ ì•„ë™"]
        res2 = sb.table("deals").select("id,title,category,source") \
            .eq("status", "active") \
            .eq("source", "community") \
            .execute()
        for d in (res2.data or []):
            cat = d.get("category", "")
            title = d.get("title", "")
            if cat in BLOCKED_CATS or is_food_or_daily(title, cat):
                sb.table("deals").update({
                    "status": "expired",
                    "admin_note": f"[ìë™ë§Œë£Œ] ì‹í’ˆ/ì¼ìƒìš©í’ˆ ì»¤ë®¤ë‹ˆí‹° ë”œ ì² ì¹™ìœ„ë°˜"
                }).eq("id", d["id"]).execute()
                logger.info(f"ğŸ—‘ ìë™ë§Œë£Œ(ì‹í’ˆ): #{d['id']} {d['title'][:35]}")

        # 3) í• ì¸ìœ¨ 10% ë¯¸ë§Œ active ë”œ ë§Œë£Œ (ë¹„ì»¤ë®¤ë‹ˆí‹° ë”œë§Œ â€” ì»¤ë®¤ë‹ˆí‹°ëŠ” MSRP ì—†ì´ ë“±ë¡)
        res3 = sb.table("deals").select("id,title,discount_rate,sale_price,source") \
            .eq("status", "active") \
            .neq("source", "community") \
            .gt("sale_price", 0) \
            .lt("discount_rate", 10) \
            .gt("discount_rate", 0) \
            .execute()
        for d in (res3.data or []):
            sb.table("deals").update({
                "status": "expired",
                "admin_note": f"[ìë™ë§Œë£Œ] í• ì¸ìœ¨ {d['discount_rate']}% < 10%"
            }).eq("id", d["id"]).execute()
            logger.info(f"ğŸ—‘ ìë™ë§Œë£Œ(í• ì¸<10%): #{d['id']} {d['title'][:35]} | {d['discount_rate']}%")

        # 4) is_hot ë™ê¸°í™”: í• ì¸ìœ¨ 40% ì´ìƒ â†’ HOT, ë¯¸ë§Œ â†’ not HOT
        res4 = sb.table("deals").select("id,discount_rate") \
            .eq("status", "active") \
            .eq("is_hot", False) \
            .gte("discount_rate", 40) \
            .execute()
        for d in (res4.data or []):
            sb.table("deals").update({"is_hot": True}).eq("id", d["id"]).execute()
            logger.info(f"â­ is_hot ë™ê¸°í™”: #{d['id']} {d['discount_rate']}%")
        # í• ì¸ìœ¨ 40% ë¯¸ë§Œì¸ë° HOTì¸ ë”œ í•´ì œ
        res4b = sb.table("deals").select("id,discount_rate") \
            .eq("status", "active") \
            .eq("is_hot", True) \
            .lt("discount_rate", 40) \
            .execute()
        for d in (res4b.data or []):
            sb.table("deals").update({"is_hot": False}).eq("id", d["id"]).execute()
            logger.info(f"â„ï¸ is_hot í•´ì œ: #{d['id']} {d['discount_rate']}%")

    except Exception as e:
        logger.error(f"âŒ cleanup_invalid_deals ì˜¤ë¥˜: {e}")
